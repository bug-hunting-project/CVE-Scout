from DB import Sqlite_Handler
from git import Repo
import os
import json
import csv
import shutil

unnecessary_files = ['README.md', '.git']

class PoC_Parser_Sqlite:
    repo_url = "https://github.com/nomi-sec/PoC-in-GitHub"
    repo_dir = "./poc"
    DB_PATH = "/home/lrtk/.cache/grype/db/5/vulnerability.db"
    TABLE_NAME = "PoC"
    CSV_PATH = "./.data/poc_data.csv"
    schema = {
        'no': 'INTEGER PRIMARY KEY AUTOINCREMENT',
        'cve_id': 'TEXT NOT NULL',
        'poc_name': 'TEXT NOT NULL',
        'html_url': 'TEXT NOT NULL',
        'description': 'TEXT'
    }

    def __init__(self):
        self.handler = Sqlite_Handler(self.DB_PATH)
        self.create_table()
        os.makedirs(self.repo_dir, exist_ok=True)

    def _remove_unnecessary_files(self):
        for file in unnecessary_files:
            file_path = os.path.join(self.repo_dir, file)
            if os.path.isfile(file_path):
                os.remove(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
    
    def create_table(self):
        if not self.handler.create_table(self.TABLE_NAME, self.schema):
            self.handler.delete_table(self.TABLE_NAME)
            print(f"Table {self.TABLE_NAME} deleted.")
        
        self.handler.create_table(self.TABLE_NAME, self.schema)
        print(f"Table {self.TABLE_NAME} created.")
    
    def clone_repo(self):
        if os.path.exists(self.repo_dir):
            shutil.rmtree(self.repo_dir)
        
        Repo.clone_from(self.repo_url, self.repo_dir)
        print(f"Repo cloned from {self.repo_url} to {self.repo_dir}")
        self._remove_unnecessary_files()
        
    def parse_json_file(self, file_path):
        with open(file_path, 'r') as file:
            data = json.load(file)
            cve_id = os.path.basename(file_path).replace('.json', '')
            return [(cve_id, entry['full_name'], entry['html_url'], entry.get('description', "")) for entry in data]

    def extract_poc_info(self):
        poc_data = []
        for root, _, files in os.walk(self.repo_dir):
            for file_name in filter(lambda f: f.endswith(".json"), files):
                poc_data.extend(self.parse_json_file(os.path.join(root, file_name)))
        print(f"Extracted {len(poc_data)} PoC entries from {self.repo_dir} and its subdirectories.")
        return poc_data

    def save_to_csv(self, data):
        headers = [key for key in self.schema.keys() if key != 'no']
        
        with open(self.CSV_PATH, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)
            writer.writerows(data)

    def import_csv_to_db(self):
        import_csv_result = self.handler.import_poc_csv(self.CSV_PATH, self.TABLE_NAME, self.schema)
        if import_csv_result:
            print("Data imported successfully.")
        else:
            print("Error occurred while importing data.")

    def save_to_db(self, data):
        self.save_to_csv(data)
        self.import_csv_to_db()
        print(f"Saved {len(data)} entries to database using CSV.")
